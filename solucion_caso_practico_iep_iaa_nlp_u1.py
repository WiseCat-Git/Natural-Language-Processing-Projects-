# -*- coding: utf-8 -*-
"""Solucion_caso_practico_IEP_IAA_NLP_u1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z_bo18F5xw9zfx1jfJzZGR7QSBIQgZMM

## Preguntas Cr√≠ticas ‚Äì Unidad 2: Pipeline de NLP

A continuaci√≥n, presentamos una serie de preguntas reflexivas para profundizar en los conceptos aprendidos sobre el pipeline de procesamiento de lenguaje natural:

### 1. Importancia de las Etapas
- ¬øCu√°l es la importancia de cada etapa del pipeline de NLP (preprocesamiento, modelado, postprocesamiento y evaluaci√≥n)?
- ¬øC√≥mo influyen estas etapas en la calidad de los resultados finales?

### 2. Preprocesamiento de Texto
- ¬øQu√© t√©cnicas de preprocesamiento son m√°s efectivas para preparar datos textuales para el modelado en NLP?
- ¬øQu√© problemas pueden surgir durante el preprocesamiento y c√≥mo se pueden evitar?

### 3. Modelado en NLP
- ¬øCu√°les son algunos de los enfoques m√°s comunes para el modelado en NLP y qu√© ventajas y desventajas tiene cada uno?
- ¬øC√≥mo se puede seleccionar el enfoque m√°s adecuado para un problema espec√≠fico?

### 4. Evaluaci√≥n del Modelo
- ¬øQu√© m√©todos de evaluaci√≥n se pueden usar para medir el rendimiento de un modelo de NLP?
- ¬øC√≥mo se puede garantizar una evaluaci√≥n justa y precisa?
- ¬øQu√© m√©tricas se deben considerar para obtener una evaluaci√≥n integral?

### 5. Evaluaci√≥n Cualitativa
- ¬øEn qu√© tareas es crucial una evaluaci√≥n cualitativa (ej. generaci√≥n de texto, traducci√≥n autom√°tica)?
- ¬øQu√© aspectos analiza esta evaluaci√≥n que no capturan las m√©tricas cuantitativas?

---

*Reflexionar sobre estas preguntas permitir√° una mejor comprensi√≥n del ciclo completo de un proyecto de NLP y ayudar√° a desarrollar soluciones m√°s robustas y responsables.*

# Caso Pr√°ctico ‚Äì Pipeline de NLP: An√°lisis de Rese√±as de Productos

## Objetivo
El objetivo de este caso pr√°ctico es construir un pipeline de procesamiento de lenguaje natural (NLP) completo que nos permita analizar rese√±as de productos (dataset de Amazon). Seguiremos las etapas t√≠picas del pipeline:

- **Preprocesamiento de texto**: Limpieza, tokenizaci√≥n, eliminaci√≥n de stopwords y lematizaci√≥n.
- **Modelado**: Clasificaci√≥n de las rese√±as como positivas o negativas usando modelos de Machine Learning.
- **Evaluaci√≥n**: Medici√≥n del rendimiento del modelo con m√©tricas cuantitativas como precisi√≥n, recall y F1-score.

## Herramientas y Librer√≠as
- `pandas`: Manipulaci√≥n de datos.
- `nltk`: Preprocesamiento de texto (tokenizaci√≥n, stopwords, lematizaci√≥n).
- `sklearn`: Construcci√≥n del modelo de clasificaci√≥n y evaluaci√≥n del rendimiento.
- `Google Colab`: Entorno de ejecuci√≥n recomendado.

## Dataset
Trabajaremos con rese√±as reales del archivo `amazon_reviews.csv`, disponible en:

> *Este ejercicio me permitir√° aplicar de forma pr√°ctica los conocimientos aprendidos sobre pipelines de NLP y reflexionar sobre su impacto en la calidad del modelo final.*
"""

# Librer√≠as necesarias
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# üîÑ Descargar recursos de NLTK (si no se han descargado)
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Cargar el dataset
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datos_IEP_IAA_NLP_u1/Unidad 1/amazon_reviews.csv')

# Ver un resumen del dataset
df.head()

# Reemplazo de word_tokenize por .split()
# Esta soluci√≥n evita el uso de 'punkt' por completo

import nltk
import re
import pandas as pd
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Descargar solo lo necesario
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Funci√≥n de preprocesamiento alternativa sin word_tokenize
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    tokens = text.split()  # ‚Üê reemplazo de nltk.word_tokenize
    stop_words = set(stopwords.words('english'))
    tokens = [t for t in tokens if t not in stop_words]
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(t) for t in tokens]
    return " ".join(tokens)

# Aplicar preprocesamiento
df['processed_review'] = df['reviewText'].astype(str).apply(preprocess_text)

# Mostrar resultados
df[['reviewText', 'processed_review']].head()

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

# Definir vectorizador TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)

# Aplicar al texto preprocesado
X = vectorizer.fit_transform(df['processed_review'])

# Etiqueta de clasificaci√≥n (puedes usar 'overall' o binarizarla si quieres sentimiento)
y = df['overall']

# Dividir en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Modelo
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predicciones
y_pred = clf.predict(X_test)

# Evaluaci√≥n
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""# **Resumen de Preprocesamiento, Vectorizaci√≥n y Modelado de Clasificaci√≥n con Random Forest**

# 1. Preprocesamiento de texto

Se aplicaron t√©cnicas de limpieza y normalizaci√≥n al texto de las rese√±as:

1. Conversi√≥n a min√∫sculas.

2. Eliminaci√≥n de HTML y puntuaci√≥n.

3. Tokenizaci√≥n con nltk.

4. Eliminaci√≥n de stopwords (palabras vac√≠as).

5. Lematizaci√≥n para reducir palabras a su forma base.

# nltk + regex + WordNetLemmatizer

# 2. Vectorizaci√≥n TF-IDF

Transformamos el texto limpio a una representaci√≥n num√©rica mediante TfidfVectorizer, limitando a las 5.000 palabras m√°s frecuentes. Esto nos permiti√≥ representar las rese√±as como vectores dispersos que reflejan la importancia de cada palabra en el corpus.

# 3. Modelo de Clasificaci√≥n con Random Forest

Se entren√≥ un modelo RandomForestClassifier para predecir la calificaci√≥n (overall) de una rese√±a en una escala de 1 a 5 estrellas.

  Divisi√≥n de los datos en conjunto de entrenamiento (80%) y prueba (20%).

  M√©trica principal: accuracy (precisi√≥n general).

  Evaluaci√≥n con classification_report.

# 4. Resultados

Accuracy general: 0.798 (aprox. 80%)

El modelo predijo casi exclusivamente la clase 5.0, lo que indica desequilibrio de clases severo en los datos.

Clases 2.0, 3.0 y 4.0 no fueron predichas correctamente (precision y recall = 0.0).

# **Conclusi√≥n**

Aunque el modelo muestra una alta precisi√≥n general, no generaliza bien a clases minoritarias. Es recomendable aplicar t√©cnicas como:

Rebalanceo de clases (oversampling, undersampling).

Clasificaci√≥n binaria (opini√≥n positiva vs negativa).

Ajuste de hiperpar√°metros o modelos alternativos.

# **Visualizaci√≥n del desequilibrio de clases y Matriz de Confusi√≥n**
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Visualizar la distribuci√≥n de clases
plt.figure(figsize=(8, 5))
sns.countplot(x='overall', data=df)
plt.title("Distribuci√≥n de Clases (Calificaciones de Rese√±as)")
plt.xlabel("Calificaci√≥n")
plt.ylabel("N√∫mero de Rese√±as")
plt.show()

"""La matriz de confusi√≥n permite visualizar los errores de predicci√≥n del modelo. Muestra c√≥mo muchas clases se predijeron incorrectamente como 5.0."""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Calcular matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred)

# Etiquetas ordenadas (asegura que coincidan con las clases)
labels = sorted(y.unique())

# Mostrar la matriz con etiquetas
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap='Blues', xticks_rotation=45)
plt.title("Matriz de Confusi√≥n - Random Forest")
plt.show()

"""## Conclusi√≥n del Caso Pr√°ctico ‚Äì Pipeline de NLP (Amazon Reviews)

En este caso pr√°ctico, desarrollamos un pipeline completo de Procesamiento de Lenguaje Natural (NLP) aplicado a rese√±as de productos de Amazon. Se llevaron a cabo las siguientes etapas clave:

- **Preprocesamiento del texto**: limpieza, tokenizaci√≥n, eliminaci√≥n de stopwords y lematizaci√≥n, para reducir ruido y estandarizar el texto.
- **Vectorizaci√≥n**: se aplic√≥ TF-IDF para representar las rese√±as como vectores num√©ricos.
- **Modelado**: se utiliz√≥ un clasificador Random Forest para predecir la calificaci√≥n (`overall`) de cada rese√±a.
- **Evaluaci√≥n**: mediante m√©tricas de rendimiento (`accuracy`, `precision`, `recall`, `f1-score`) y una matriz de confusi√≥n.

### Resultados observados:

- **Accuracy general**: aproximadamente 79.8%, lo cual indica una buena capacidad de predicci√≥n general.
- **Distribuci√≥n de predicciones**: el modelo predice de forma casi exclusiva la clase 5.0, lo que refleja un fuerte **desbalance en el dataset**, donde las rese√±as positivas son mayor√≠a.
- **Matriz de confusi√≥n**: muestra que las clases 1.0 a 4.0 no son bien representadas, con casi todas las predicciones cayendo en la clase 5.0.

### Limitaciones:

- El modelo presenta **sesgo hacia la clase dominante** (5.0), lo cual es com√∫n en datasets desbalanceados.
- Algunas clases (2.0, 3.0, 4.0) tienen pocas muestras y no se predicen correctamente.
- El modelo no incorpora validaci√≥n cruzada ni ajuste de hiperpar√°metros.

### Recomendaciones autocriticas para mi, para mejoras futuras:

1. Aplicar **t√©cnicas de balanceo de clases** (submuestreo, sobremuestreo o SMOTE).
2. Explorar **clasificaci√≥n binaria** (positivo vs negativo) o agrupaci√≥n de clases.
3. Probar otros modelos (e.g., `LogisticRegression`, `XGBoost`, `NaiveBayes`) y hacer ajuste de hiperpar√°metros.
4. Implementar **evaluaci√≥n cruzada (cross-validation)** para validar la robustez del modelo.
5. Explorar representaciones m√°s avanzadas como **Word2Vec o embeddings con BERT**.

Este ejercicio demuestra c√≥mo construir y evaluar un pipeline completo de NLP en un problema real, destacando la importancia del preprocesamiento, el balance de clases y la selecci√≥n del modelo en el rendimiento final.

## Preguntas Cr√≠ticas ‚Äì Unidad 2: Pipeline de NLP

A continuaci√≥n se presentan las respuestas razonadas a las preguntas clave planteadas al inicio del caso pr√°ctico, con base en la experiencia aplicada durante el desarrollo del pipeline de an√°lisis de rese√±as de productos.

---

### 1. Importancia de las Etapas

**¬øCu√°l es la importancia de cada etapa del pipeline de NLP?**

- **Preprocesamiento**: Transforma texto crudo en una representaci√≥n estandarizada, eliminando ruido y ambig√ºedad. Esta etapa es cr√≠tica para el √©xito del modelado.
- **Modelado**: Es el n√∫cleo del pipeline, donde se extraen patrones y se generan predicciones a partir de los datos vectorizados.
- **Postprocesamiento**: Afina los resultados del modelo, permite su interpretaci√≥n y prepara los outputs para consumo externo.
- **Evaluaci√≥n**: Permite medir el rendimiento, identificar errores y guiar mejoras. Sin una evaluaci√≥n s√≥lida, no se puede confiar en los resultados.

**¬øC√≥mo influyen estas etapas en la calidad de los resultados?**

Cada etapa act√∫a como un filtro: errores o negligencias en las primeras fases (como el preprocesamiento) se amplifican en el modelado y evaluaci√≥n. Un pipeline s√≥lido y bien definido mejora la generalizaci√≥n del modelo y reduce errores de interpretaci√≥n o sesgo.

---

### 2. Preprocesamiento de Texto

**¬øQu√© t√©cnicas son m√°s efectivas?**

- **Tokenizaci√≥n**, **eliminaci√≥n de stopwords**, **lematizaci√≥n** y **normalizaci√≥n** son fundamentales.
- TF-IDF funcion√≥ como una buena t√©cnica de vectorizaci√≥n en este ejercicio.

**¬øQu√© problemas pueden surgir y c√≥mo evitarlos?**

- Palabras mal tokenizadas, ruido HTML o puntuaci√≥n residual pueden alterar los vectores.
- Evitarlo requiere una limpieza rigurosa y validaciones en las funciones aplicadas (e.g., `.lower()`, regex bien definidas).

---

### 3. Modelado en NLP

**¬øQu√© enfoques son comunes y cu√°les son sus pros/contras?**

- **Modelos cl√°sicos**: `Naive Bayes`, `SVM`, `Random Forest`. Son r√°pidos y f√°ciles de interpretar, pero menos precisos para tareas sem√°nticas complejas.
- **Modelos basados en embeddings**: `Word2Vec`, `GloVe`, `FastText`. Capturan relaciones sem√°nticas, mejorando tareas como clasificaci√≥n o similitud.
- **Transformers (BERT, GPT)**: Precisi√≥n muy alta en tareas complejas. Requieren m√°s recursos y datos.

**¬øC√≥mo seleccionar el mejor enfoque?**

Depende del objetivo, la cantidad de datos, el balance de clases y la necesidad de interpretabilidad. Para un problema simple como clasificaci√≥n de rese√±as, un modelo tradicional como `Random Forest` fue adecuado como primer paso.

---

### 4. Evaluaci√≥n del Modelo

**¬øQu√© m√©todos se pueden usar?**

- **M√©tricas cuantitativas**: Accuracy, Precision, Recall, F1-Score, Matriz de Confusi√≥n.
- **Evaluaci√≥n cruzada** (k-fold) para verificar robustez del modelo.

**¬øC√≥mo garantizar una evaluaci√≥n justa?**

- Asegurarse de que el dataset est√© balanceado o aplicar t√©cnicas para compensar desbalances.
- Usar m√∫ltiples m√©tricas, no solo accuracy.

**¬øQu√© m√©tricas considerar?**

- **F1-score** para tareas con clases desbalanceadas.
- **Recall y Precision** cuando los falsos positivos/negativos tienen diferente importancia.
- **Matriz de confusi√≥n** para entender el comportamiento del modelo por clase.

---

### 5. Evaluaci√≥n Cualitativa

**¬øEn qu√© tareas es cr√≠tica?**

- Generaci√≥n de texto (chatbots, res√∫menes).
- Traducci√≥n autom√°tica.
- Clasificaci√≥n sensible (opiniones, diagn√≥stico m√©dico).

**¬øQu√© aspectos cubre que no capturan las m√©tricas cuantitativas?**

- **Fluidez**, **coherencia**, **tono**, **intenci√≥n** y **comprensi√≥n contextual**.
- Detecta errores sutiles o sesgos que pueden pasar desapercibidos en una m√©trica num√©rica.

---

**Reflexi√≥n Final**: Este caso pr√°ctico evidencia que el pipeline de NLP no solo es una estructura t√©cnica, sino tambi√©n un enfoque metodol√≥gico para construir soluciones robustas, √©ticas y adaptables. Invertir tiempo en cada etapa asegura resultados m√°s confiables y alineados con los objetivos del negocio o investigaci√≥n.
"""